{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7239a9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "import torch.nn.functional as F\n",
    "import functools\n",
    "from torch.optim import Adam\n",
    "import torchvision.transforms as transforms\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a8e92f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Dataset 定義\n",
    "# --------------------------\n",
    "class PCamDataset(Dataset):\n",
    "    def __init__(self, h5_x_path, h5_y_path=None, transform=None):\n",
    "        self.x_path = h5_x_path\n",
    "        self.y_path = h5_y_path\n",
    "        self.transform = transform\n",
    "        self.has_labels = h5_y_path is not None\n",
    "\n",
    "        with h5py.File(h5_x_path, 'r') as x_file:\n",
    "            self.length = len(x_file['x'])\n",
    "\n",
    "        if self.has_labels:\n",
    "            with h5py.File(h5_y_path, 'r') as y_file:\n",
    "                self.labels = y_file['y'][:]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        with h5py.File(self.x_path, 'r') as x_file:\n",
    "            image = x_file['x'][idx].astype(np.uint8)\n",
    "\n",
    "        image = transforms.ToPILImage()(image)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if self.has_labels:\n",
    "            label = self.labels[idx].item()\n",
    "            return image, label\n",
    "        else:\n",
    "            return image\n",
    "\n",
    "# --------------------------\n",
    "# パスと設定\n",
    "# --------------------------\n",
    "TRAIN_X = 'camelyonpatch_level_2_split_train_x.h5'\n",
    "TRAIN_Y = 'camelyonpatch_level_2_split_train_y.h5'\n",
    "VAL_X   = 'valid_x_uncompressed.h5'\n",
    "VAL_Y   = 'valid_y_uncompressed.h5'\n",
    "TEST_X  = 'camelyonpatch_level_2_split_test_x.h5'\n",
    "TEST_Y  = 'camelyonpatch_level_2_split_test_y.h5'\n",
    "\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "# --------------------------\n",
    "# Transform\n",
    "# --------------------------\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(96, scale=(0.6, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(45),\n",
    "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.05),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.15, 0.15)),\n",
    "    transforms.RandomPerspective(distortion_scale=0.3, p=0.5),\n",
    "    transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)),\n",
    "    transforms.RandomApply([transforms.RandomSolarize(threshold=0.5, p=0.3)], p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "    transforms.RandomErasing(p=0.5, scale=(0.02, 0.1), ratio=(0.3, 3.3)),\n",
    "])\n",
    "\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.Resize(96),\n",
    "    transforms.CenterCrop(96),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "# --------------------------\n",
    "# Dataloader\n",
    "# --------------------------\n",
    "batch_size = 128\n",
    "train_ds = PCamDataset(TRAIN_X, TRAIN_Y, transform=train_transform)\n",
    "val_ds   = PCamDataset(VAL_X, VAL_Y, transform=eval_transform)\n",
    "test_ds  = PCamDataset(TEST_X, TEST_Y, transform=eval_transform)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader   = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "test_loader  = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "# --------------------------\n",
    "# 損失関数・最適化・スケジューラ\n",
    "# --------------------------\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5cb82aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Dropout(p=0.5, inplace=False)\n",
       "    (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=512, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet50\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# モデル構築\n",
    "model = resnet50(weights=None)\n",
    "model.fc = nn.Sequential(\n",
    "    nn.BatchNorm1d(model.fc.in_features),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(model.fc.in_features, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(512),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(512, 1)\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "# 重み読み込み\n",
    "model.load_state_dict(torch.load('best_resnet50_pcam.pth', map_location=device))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aec401dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm_attack(model, images, labels, epsilon):\n",
    "    images = images.clone().detach().to(device)\n",
    "    labels = labels.clone().detach().to(device)\n",
    "    images.requires_grad = True\n",
    "\n",
    "    outputs = model(images)\n",
    "    loss = criterion(outputs, labels)\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    # FGSM perturbation: sign(∇_x loss)\n",
    "    perturbed_images = images + epsilon * images.grad.sign()\n",
    "    perturbed_images = torch.clamp(perturbed_images, 0, 1)\n",
    "    return perturbed_images\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def evaluate_fgsm(loader, epsilon):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "\n",
    "    for imgs, labels in loader:\n",
    "        imgs, labels = imgs.to(device), labels.float().unsqueeze(1).to(device)\n",
    "        \n",
    "        # FGSM攻撃で画像を摂動\n",
    "        adv_imgs = fgsm_attack(model, imgs, labels, epsilon)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(adv_imgs)\n",
    "            probs = torch.sigmoid(outputs)\n",
    "            preds = (probs > 0.5).long()\n",
    "\n",
    "            correct += (preds == labels.long()).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    acc = correct / total\n",
    "    auc = roc_auc_score(all_labels, all_probs)\n",
    "\n",
    "    print(f\"FGSM attack (epsilon={epsilon}) Accuracy: {acc * 100:.2f}%\")\n",
    "    print(f\"FGSM attack (epsilon={epsilon}) ROC-AUC: {auc:.4f}\")\n",
    "    return acc, auc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f45ded0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FGSM attack (epsilon=0.3) Accuracy: 44.53%\n",
      "FGSM attack (epsilon=0.3) ROC-AUC: 0.4276\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4453125, 0.42755601070859434)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epsilon = 0.3  # 摂動の強さ（適宜調整）\n",
    "evaluate_fgsm(val_loader, epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "236206a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "device = 'cuda' #@param ['cuda', 'cpu'] {'type':'string'}\n",
    "\n",
    "def marginal_prob_std(t, sigma):\n",
    "  \"\"\"Compute the mean and standard deviation of $p_{0t}(x(t) | x(0))$.\n",
    "\n",
    "  Args:    \n",
    "    t: A vector of time steps.\n",
    "    sigma: The $\\sigma$ in our SDE.  \n",
    "  \n",
    "  Returns:\n",
    "    The standard deviation.\n",
    "  \"\"\"    \n",
    "  t = torch.tensor(t, device=device)\n",
    "  return torch.sqrt((sigma**(2 * t) - 1.) / 2. / np.log(sigma))\n",
    "\n",
    "def diffusion_coeff(t, sigma):\n",
    "  \"\"\"Compute the diffusion coefficient of our SDE.\n",
    "\n",
    "  Args:\n",
    "    t: A vector of time steps.\n",
    "    sigma: The $\\sigma$ in our SDE.\n",
    "  \n",
    "  Returns:\n",
    "    The vector of diffusion coefficients.\n",
    "  \"\"\"\n",
    "  return torch.tensor(sigma**t, device=device)\n",
    "  \n",
    "sigma =  10.0#@param {'type':'number'}\n",
    "marginal_prob_std_fn = functools.partial(marginal_prob_std, sigma=sigma)\n",
    "diffusion_coeff_fn = functools.partial(diffusion_coeff, sigma=sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "31d08620",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def loss_fn(model, x, marginal_prob_std, eps=1e-5):\n",
    "  random_t = torch.rand(x.shape[0], device=x.device) * (1. - eps) + eps  \n",
    "  z = torch.randn_like(x)\n",
    "  std = marginal_prob_std(random_t)\n",
    "  perturbed_x = x + z * std[:, None, None, None]\n",
    "\n",
    "  start = time.time()   # ←ここを追加\n",
    "  score = model(perturbed_x, random_t)\n",
    "\n",
    "  loss = torch.mean(torch.sum((score * std[:, None, None, None] + z)**2, dim=(1,2,3)))\n",
    "  return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4f244539",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pc_sampler(score_model, \n",
    "               marginal_prob_std,\n",
    "               diffusion_coeff,\n",
    "               batch_size=64, \n",
    "               num_steps=500, \n",
    "               snr=0.16,                 \n",
    "               device='cuda',\n",
    "               eps=1e-3,\n",
    "               init_x=None):\n",
    "    \n",
    "    t = torch.ones(batch_size, device=device)\n",
    "\n",
    "    if init_x is None:\n",
    "        init_x = torch.randn(batch_size, 3, 96, 96, device=device) * marginal_prob_std(t)[:, None, None, None]\n",
    "    else:\n",
    "        init_x = init_x.to(device)\n",
    "        if init_x.shape[2:] != (96, 96):\n",
    "            import torch.nn.functional as F\n",
    "            init_x = F.interpolate(init_x, size=(96, 96), mode='bilinear', align_corners=False)\n",
    "    \n",
    "    time_steps = np.linspace(1., eps, num_steps)\n",
    "    step_size = time_steps[0] - time_steps[1]\n",
    "    x = init_x\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for time_step in tqdm.tqdm(time_steps, desc=\"PC Sampling\"):\n",
    "            batch_time_step = torch.ones(batch_size, device=device) * time_step\n",
    "\n",
    "            # Langevin MCMC (Corrector step)\n",
    "            grad = score_model(x, batch_time_step)\n",
    "            grad_norm = torch.norm(grad.reshape(grad.shape[0], -1), dim=-1).mean()\n",
    "            grad_norm = torch.clamp(grad_norm, min=1e-5)  # ← 数値安定化\n",
    "\n",
    "            noise_norm = np.sqrt(np.prod(x.shape[1:]))\n",
    "            langevin_step_size = 2 * (snr * noise_norm / grad_norm) ** 2\n",
    "\n",
    "            x = x + langevin_step_size * grad + torch.sqrt(2 * langevin_step_size) * torch.randn_like(x)\n",
    "\n",
    "            # Euler-Maruyama (Predictor step)\n",
    "            g = diffusion_coeff(batch_time_step).view(-1, 1, 1, 1)\n",
    "            score = score_model(x, batch_time_step)\n",
    "            x_mean = x + (g ** 2) * score * step_size\n",
    "            x = x_mean + torch.sqrt(g ** 2 * step_size) * torch.randn_like(x)\n",
    "\n",
    "    return x_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "85404825",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class GaussianFourierProjection(nn.Module):\n",
    "  \"\"\"Gaussian random features for encoding time steps.\"\"\"  \n",
    "  def __init__(self, embed_dim, scale=30.):\n",
    "    super().__init__()\n",
    "    # Randomly sample weights during initialization. These weights are fixed \n",
    "    # during optimization and are not trainable.\n",
    "    self.W = nn.Parameter(torch.randn(embed_dim // 2) * scale, requires_grad=False)\n",
    "  def forward(self, x):\n",
    "    x_proj = x[:, None] * self.W[None, :] * 2 * np.pi\n",
    "    return torch.cat([torch.sin(x_proj), torch.cos(x_proj)], dim=-1)\n",
    "\n",
    "\n",
    "class Dense(nn.Module):\n",
    "  \"\"\"A fully connected layer that reshapes outputs to feature maps.\"\"\"\n",
    "  def __init__(self, input_dim, output_dim):\n",
    "    super().__init__()\n",
    "    self.dense = nn.Linear(input_dim, output_dim)\n",
    "  def forward(self, x):\n",
    "    return self.dense(x)[..., None, None]\n",
    "\n",
    "class ScoreNet(nn.Module):\n",
    "  def __init__(self, marginal_prob_std, channels=[32, 64, 128, 256], embed_dim=256):\n",
    "    super().__init__()\n",
    "    self.embed = nn.Sequential(\n",
    "        GaussianFourierProjection(embed_dim=embed_dim),\n",
    "        nn.Linear(embed_dim, embed_dim)\n",
    "    )\n",
    "    \n",
    "    self.conv1 = nn.Conv2d(3, channels[0], 3, stride=1, padding=1, bias=False)  # 入力チャネル変更\n",
    "    self.dense1 = Dense(embed_dim, channels[0])\n",
    "    self.gnorm1 = nn.GroupNorm(4, num_channels=channels[0])\n",
    "\n",
    "    self.conv2 = nn.Conv2d(channels[0], channels[1], 3, stride=2, padding=1, bias=False)\n",
    "    self.dense2 = Dense(embed_dim, channels[1])\n",
    "    self.gnorm2 = nn.GroupNorm(32, num_channels=channels[1])\n",
    "\n",
    "    self.conv3 = nn.Conv2d(channels[1], channels[2], 3, stride=2, padding=1, bias=False)\n",
    "    self.dense3 = Dense(embed_dim, channels[2])\n",
    "    self.gnorm3 = nn.GroupNorm(32, num_channels=channels[2])\n",
    "\n",
    "    self.conv4 = nn.Conv2d(channels[2], channels[3], 3, stride=2, padding=1, bias=False)\n",
    "    self.dense4 = Dense(embed_dim, channels[3])\n",
    "    self.gnorm4 = nn.GroupNorm(32, num_channels=channels[3])    \n",
    "\n",
    "    self.tconv4 = nn.ConvTranspose2d(channels[3], channels[2], 4, stride=2, padding=1, bias=False)\n",
    "    self.dense5 = Dense(embed_dim, channels[2])\n",
    "    self.tgnorm4 = nn.GroupNorm(32, num_channels=channels[2])\n",
    "\n",
    "    self.tconv3 = nn.ConvTranspose2d(channels[2]+channels[2], channels[1], 4, stride=2, padding=1, bias=False)\n",
    "    self.dense6 = Dense(embed_dim, channels[1])\n",
    "    self.tgnorm3 = nn.GroupNorm(32, num_channels=channels[1])\n",
    "\n",
    "    self.tconv2 = nn.ConvTranspose2d(channels[1]+channels[1], channels[0], 4, stride=2, padding=1, bias=False)\n",
    "    self.dense7 = Dense(embed_dim, channels[0])\n",
    "    self.tgnorm2 = nn.GroupNorm(32, num_channels=channels[0])\n",
    "\n",
    "    self.tconv1 = nn.ConvTranspose2d(channels[0]+channels[0], 3, 3, stride=1, padding=1)  # 出力チャネル変更\n",
    "\n",
    "    self.act = lambda x: x * torch.sigmoid(x)\n",
    "    self.marginal_prob_std = marginal_prob_std\n",
    "\n",
    "  def forward(self, x, t): \n",
    "    embed = self.act(self.embed(t))\n",
    "    h1 = self.act(self.gnorm1(self.conv1(x) + self.dense1(embed)))\n",
    "    h2 = self.act(self.gnorm2(self.conv2(h1) + self.dense2(embed)))\n",
    "    h3 = self.act(self.gnorm3(self.conv3(h2) + self.dense3(embed)))\n",
    "    h4 = self.act(self.gnorm4(self.conv4(h3) + self.dense4(embed)))\n",
    "\n",
    "    h = self.act(self.tgnorm4(self.tconv4(h4) + self.dense5(embed)))\n",
    "    h = self.act(self.tgnorm3(self.tconv3(torch.cat([h, h3], dim=1)) + self.dense6(embed)))\n",
    "    h = self.act(self.tgnorm2(self.tconv2(torch.cat([h, h2], dim=1)) + self.dense7(embed)))\n",
    "    h = self.tconv1(torch.cat([h, h1], dim=1))\n",
    "\n",
    "    h = h / self.marginal_prob_std(t)[:, None, None, None]\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c4ca644a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# モデル・関数の事前定義（省略していた場合は必要）\n",
    "# → ScoreNet, marginal_prob_std_fn, loss_fn 等は定義済みと仮定\n",
    "# -------------------------------\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import functools\n",
    "import h5py\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import tqdm\n",
    "import os\n",
    "\n",
    "class PCamDataset_k(Dataset):\n",
    "    def __init__(self, x_path, y_path, transform=None):\n",
    "        super().__init__()\n",
    "        self.x_h5 = h5py.File(x_path, 'r')\n",
    "        self.y_h5 = h5py.File(y_path, 'r')\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.x_h5['x'].shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.x_h5['x'][idx]\n",
    "        if img.ndim == 2:\n",
    "            img = np.stack([img]*3, axis=-1)\n",
    "        elif img.shape[2] == 1:\n",
    "            img = np.concatenate([img]*3, axis=2)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        label = self.y_h5['y'][idx]\n",
    "        return img, label\n",
    "\n",
    "\n",
    "# ----------- パラメータ -------------\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "n_epochs = 500\n",
    "batch_size = 16\n",
    "lr = 2e-4\n",
    "sigma = 10.0\n",
    "marginal_prob_std_fn = functools.partial(lambda t, sigma: torch.sqrt((sigma**(2 * t) - 1.) / 2. / np.log(sigma)), sigma=sigma)\n",
    "\n",
    "# ----------- モデルとデータ -------------\n",
    "# データローダーの正規化を修正\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # [-1,1]に正規化\n",
    "])\n",
    "\n",
    "dataset = PCamDataset_k(\n",
    "    '/home/gotou/Medical/camelyonpatch_level_2_split_train_x.h5',\n",
    "    '/home/gotou/Medical/camelyonpatch_level_2_split_train_y.h5',\n",
    "    transform=transform\n",
    ")\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "score_model = ScoreNet(marginal_prob_std=marginal_prob_std_fn).to(device)\n",
    "optimizer = Adam(score_model.parameters(), lr=lr, betas=(0.9, 0.99))\n",
    "best_loss = 1000\n",
    "\n",
    "\n",
    "# ----------- 損失関数 -------------\n",
    "def loss_fn(model, x, marginal_prob_std, eps=1e-5):\n",
    "    random_t = torch.rand(x.shape[0], device=x.device) * (1. - eps) + eps  \n",
    "    z = torch.randn_like(x)\n",
    "    std = marginal_prob_std(random_t)\n",
    "    perturbed_x = x + z * std[:, None, None, None]\n",
    "    score = model(perturbed_x, random_t)\n",
    "    loss = torch.mean(torch.sum((score * std[:, None, None, None] + z)**2, dim=(1,2,3)))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "360ccba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PC Sampling:   0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_298657/3662202757.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(sigma**t, device=device)\n",
      "PC Sampling: 100%|██████████| 500/500 [00:04<00:00, 113.78it/s]\n"
     ]
    }
   ],
   "source": [
    "# 学習済みモデルの読み込み\n",
    "score_model.load_state_dict(torch.load('ckpt_epoch_1000.pth', map_location=device))\n",
    "score_model.eval()\n",
    "\n",
    "# サンプリング\n",
    "samples = pc_sampler(score_model, marginal_prob_std_fn, diffusion_coeff_fn,\n",
    "                     batch_size=16, num_steps=500, device=device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
